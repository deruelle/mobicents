<?xml version='1.0'?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
]>
<section
	id="section-Mobicents_Media_Server_Architecture">
	<title>Mobicents Media Server Architecture</title>
	<para>Media services have played an important role in the traditional Time Division Multiplexing (<acronym>TDM</acronym>)-based telephone network. As the network migrates to an Internet Protocol (<acronym>IP</acronym>)-based environment, media services are also moving to new environments.</para>
	<para>One of the most exciting trends is the emergence and adoption of complementary modular standards that leverage the Internet to enable media services to be developed, deployed and updated more rapidly than before in a network architecture that supports the two concepts we will call provisioning-on-demand and scaling-on-demand.</para>
	<!-- <para>Media services have played an important role in the traditional time division multiplexing (TDM)-based telephone network. As the network migrates to an Internet Protocol (IP)-based environment, media services are also moving to new environments.  One of the most exciting trends is the emergence and adoption of complementary modular standards that leverage the Internet to enable media services to be developed, deployed, and updated more rapidly than before in a network architecture that supports concepts we call provisioning on demand and scaling on demand.</para> -->
	<section
		id="section-Design_Overview_and_Typical_Deployment_Scenario">
		<title>Design Overview and Typical Deployment Scenario</title>
		<formalpara>
			<title>General Design Overview</title>
			<para>Mobicents Media Server is developed on top of existing Java technologies. The Java platform is the ideal platform for network computing. It offers a single, unifying programming model that can connect all elements of a business infrastructure. The modularization effort is supported by the use of the Java Management Extension (<acronym>JMX</acronym>) <acronym>API</acronym>, and the industry-standard Service Logic Execution Environment (<acronym>SLEE</acronym>) container. Using JMX enables easy management of both the server's media components and the control modules hosted by <acronym>SLEE</acronym>.</para>
		</formalpara>
 <!-- 
General disign overview.
 
Mobicents Media server is developed on top of the existing Java Techologies. The Java platform is the ideal platform for network computing. It offers a single, unifying programming model that can connect all elements of a business infrastructure. The modularization effort is supported by the use of JMX, Java Management Extension API and the industry standard SLEE container. Using JMX help manage both server's media components and control modules hosted by SLEE. -->
		<para>This high degree of modularity benefits the application developer in several ways. The already-tight code can be further trimmed down to support applications that must have small footprints. For example, if <acronym>PSTN</acronym> (Public Switched Telephone Network) interconnection is unnecessary in your application, then simply take the D-channel feature out of the server. If you later decide to deploy the same application within a Signaling System 7 (<acronym>SS7</acronym>) network, then simply enable the appropriate endpoint. Another example is the freedom you have to drop your favorite media control protocol directly into the <acronym>SLEE</acronym> container.</para>
<!--
This hi-degree of modularity benefits the application developer in several ways. The already tight code can be further trimmed down to support application that must have a small footprint. For example if PSTN interconnection is unnecessary in your application simply take the D-channel feature out of the server. If you later decide to deploy same application withing an SS7 network simply enable the appropriate endpoint. Another example is the freedom you have to drop your favorite Media Control Protocol directly into the SLEE container.-->
		<figure
			id="figure-Media_Server_Overview">
			<title>Media Server Overview</title>
			<mediaobject>
				<imageobject>
					<imagedata
						align="left"
						fileref="images/sas-MMSArchitecture-MSGeneral.jpg"
						format="JPG"/>
				</imageobject>
			</mediaobject>
		</figure>
		<!--<remark>
		Silas: This section removed from the text because JMF has been removed in favor of a custom Player and Recorder implementation.
		<para>The components that are involved in media processing or endpoints are implemented with <acronym>JMF</acronym>, the Java Media Framework. JMF provides a platform-neutral framework for displaying time-sensitive media. The <acronym>JMF</acronym> <acronym>API</acronym>:</para>
		<itemizedlist>
			<listitem>
				<para>Scales across different protocols and delivery mechanisms</para>
			</listitem>
			<listitem>
				<para>Scales across different types of media data</para>
			</listitem>
			<listitem>
				<para>Provides an event model for asynchnronous communication between JMF and applications or applets</para>
			</listitem>
		</itemizedlist>
		<para>The <acronym>JMF</acronym> architecture allows advanced developers nto create and integrate new types of controllers and data sources. The <acronym>JMF</acronym> <acronym>API</acronym> declares abstract interfaces which are used for handling new media sources and sinks such as audio and video files, <acronym>PSTN</acronym> cards, webcams, etc.</para></remark>-->
		<para>The Media Server architecture assumes that call control intelligence is outside of the Media Server and handled by an external entity. The Media Server assumes that call controllers will use control procedures such as <acronym>MGCP</acronym>, Mecago or <acronym>MSML</acronym>, among others. Each specific control module can be plugged in directly to the server as a standard <acronym>SLEE</acronym> deployable unit. The usage of a <acronym>SLEE</acronym> container for the implementation of the control protocol-specific communication logic provides simple deployment and also the easy deployment of such control modules. The developer will not have to mess with low-level transaction and state management details, multi-threading, connection-pooling and other similar complex, low-level <acronym>API</acronym>s.</para>
		<note>
			<para>The Mobicents Media Server uses <acronym>SLEE</acronym> for implementing its own communication capabilities. The <acronym>SLEE</acronym> container doesn't serve here as a call controller.</para>
		</note>

<!--The components that are involved into media processing or Endpoints are implemented with JMF, Java Media Framework. JMF provides a platform neutral framework for displaing time-based media. The JMF API:

    * Scales across different protocols and delivery mechanisms
    * Scales across different types of media data
    * Provides an event model for asynchronous communication between JMF and applications or applets.

The JMF architecture allows advanced developers to create and integrate new types of controllers and data sources. JMF API declares abstract interfaces which used for handling new media sources or sinks like audio/video files, PSTN cards, web cams, etc.
 
Media server architecture assumes that call controll intelligence is outside of the Media Server and handled by external entity. Media Server assumes that call controllers will use any of controll protocols such as MGCP, Mecago, MSML or others. Each specific control module can be pluged-in directly to the server as standard SLEE deployable unit. The usage of SLEE container for the implementation of the control protocol specific communication logic provides simple development and deployment of such control modules. The developer will not have to low-level transaction and state management details, multi-threading, connection pooling and other low level complex APIs.
 
Note. Media Server uses SLEE for implementing its own communication capabilities. SLEE container doesn't serve here as call controller.-->
		<para>In addition to control protocol modules, the <acronym>SLEE</acronym> container is aimed at providing high-level features like Interactive Voice Response (<acronym>IVR</acronym>) and Drools or VoiceXML engines.</para>
<!--
In addition to control protocol modules the SLEE container is aimed to provide high-level features like IVR &amp; Drools or VoiceXML  engines.
-->
		<para>The modules deployed under <acronym>SLEE</acronym> control interact with the Media Server Service Provider Interface (<acronym>SPI</acronym>) through the Media Server Control Resource Adapter, or <acronym>MSC-RA</acronym>. The <acronym>MSC-RA</acronym> follows the recommendations of JSR-309 and implements asynchronous interconnection with the Media Server <acronym>SPI</acronym> stack. This local implementation is restricted and does not all the use of high-level abstractions like VoiceXML dialogs, <abbrev>etc.</abbrev>.</para>
<!--
The modules deployed under SLEE control interact with Media Server SPI though Media Server Control Resource Adapter. The MSC-RA follows to recomndations of JSR-309 and implements asynchronous interconnection with Media Server SPI stack. This local implementation is restricted and does not allow to use high level abstraction like Voice XML dialogs, etc.
-->
		<formalpara>
			<title>Typical Deployment Scenario</title>
			<para>Mobicents Media Server offers a complete solution for all aspects of being a media gateway and server. This includes the Digital Signal Processors required to covert and compress <acronym>TDB</acronym> voice circuits into <acronym>IP</acronym> packets, announcement access points, conferencing, high-level IVR engines, <abbrev>etc.</abbrev> The gateway is able to provide signaling conversation and can operate as a Session Border Controller at the boundaries of Local Access Networks. The Media Server is always controlled by an external <acronym>JBCP</acronym> application server which implements the call control logic.</para>
		</formalpara>
		<mediaobject
			id="mediaobj-sas-MMSArchitecture-MSDeployment.gif">
			<imageobject>
				<imagedata
					align="left"
					fileref="images/sas-MMSArchitecture-MSDeployment.gif"
					format="GIF"/>
			</imageobject>
			<caption>
				<para>Typical Deployment Scenario</para>
			</caption>
		</mediaobject>
	</section>
<!--
Typical deployment scenario.
 
Mobicent Media Server offers a complete solution for all aspects of media gateway and media server. This is include the Digital Signal Processors required to convert and compress TDM voice circuits into IP packets, Announcement access points, Conferencing, hi-level IVR engines, etc. The gateway is able to provide signalling conversation and can operate as Session Border Controller at the boundaries of the LANs.  The Media Server is always controlled by external JBCP Application server which implements the call control logic.
-->
	<section
		id="section-Endpoints">
		<title>Endpoints</title>
		<formalpara>
			<title>Endpoints</title>
			<para>It is convenient to consider a media gateway as a collection of endpoints. An endpoint is a logical representation of a physical entity such as an analog phone or a channel in a trunk. Endpoints are sources or sinks of data and can be physical or virtual. Physical endpoint creation requires hardware installation whil esoftware is sufficient for creating a virtual endpoint. An interface on a gateway that terminates a trunk connected to a PSTN switch is an example of a physical endpoint. An audio source in an audio content server is an example of a virtual endpoint.</para>
		</formalpara>
<!--
3.1 Endpoints. 
 
It is convinient to consider media gateway as a collection of endpoints. An Endpoint is a logical representation of a physical entity, such as an analog phone or a channel in a trunk. Endpoints are sources or sinks of data and can be physical or virtual. Physical Endpoint creation requires hardware installation while software is sufficient for creating a virtual Endpoint. An interface on a gateway that terminates a trunk connected to a PSTN switch is an example of a physical Endpoint. An audio source in an audio-content server is an example of a virtual Endpoint.-->
		<para>The type of the endpoint determines its functionality. Our analysis, so far, has led us to isolate the following basic endpoint types:</para>
		<itemizedlist>
			<listitem>
				<para>Digital Signal 0 (<acronym>DS0</acronym>)</para>
			</listitem>
			<listitem>
				<para>Analog line</para>
			</listitem>
			<listitem>
				<para>Announcement server access point</para>
			</listitem>
			<listitem>
				<para>Conference bridge acces point</para>
			</listitem>
			<listitem>
				<para>Packet relay</para>
			</listitem>
			<listitem>
				<para>Asynchronous Transfer Mode (<acronym>ATM</acronym>) &quot;trunk side&quot; interface</para>
			</listitem>
		</itemizedlist>
<!--
The type of the endpoint determines its functionality. Our analysis,so far,has led us to isolate the following basic endpoint types:

    * Digital channel (DS0),
    * Analog line,
    * Announcement server access point,
    * Interactive Voice Response access point,
    * Conference bridge access point,
    * Packet relay,
    * ATM "trunk side"interface. -->
		<para>This list is not exhaustive: there may be other types of endpoints defined in the future, for example test endpoints that could be used to check network quality, or frame-relay endpoints that could be used to manage audio channels multiplexed over a frame-relay virtual circuit.</para>
<!--
This list is not final.There may be other types of endpoints defined in the future,for example test endpoints that could be used to check network quality,or frame-relay endpoints that could be used to manage audio channels multiplexed over a frame-relay virtual circuit.
-->
		<variablelist>
			<title>Description of Various Access Point Types</title>
			<varlistentry>
				<term>Announcement Server Access Point</term>
				<listitem>
					<para>An announcement server endpoint naturally provides access to an announcement server. Upon receiving requests from the call agent, the announcement server will &quot;play&quot; a specified announcement. A given announcement endpoint is not expected to support more than one connection at a time. Connections to an announcement server are typically one-way, or &quot;half-duplex&quot;:the announcement server is not expected to listen to the audio signals from the connection.</para>
<!--			Announcement Server Access Point

An announcement server endpoint provides access to an announcement service.  Under requests from the Call Agent, the announcement server will "play" a specified announcement.  A given announcement endpoint is not expected to support more than one connection at a time. Connections to an announcement server are typically one way, or "half  duplex" - the announcement server is not expected to listen to the audio signals from the connection.-->
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Interactive Voice Response Access Point</term>
				<listitem>
					<para>An Interactive Voice Repsonse (<acronym>IVR</acronym>) endpoint provides access to an <acronym>IVR</acronym> service. Upon requests from the call agent, the <acronym>IVR</acronym> server will &quot;play&quot; announcements and tones, and will &quot;listen&quot; to responses, such as (<acronym>DTMF</acronym>) input or voice messages, from the user. A given <acronym>IVR</acronym> endpoint is not expected to support more than one connection at a time.</para>
<!--			Interactive Voice Response Access Point

An Interactive Voice Response (IVR) endpoint provides access to an IVR service.  Under requests from the Call Agent, the IVR server will "play" announcements and tones, and will "listen" to responses, such as DTMF input or voice messages, from the user. A given IVR endpoint is not expected to support more than one connection at a time.-->
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Conference Bridge Access Point</term>
				<listitem>
					<para>A conference bridge endpoint is used to provide access to a specific conference. Media gateways should be able to establish several connections between the endpoint and the packet networks, or between the endpoint and other endpoints in the same gateway. The signals originating from these connections shall be mixed according to the connection &quot;mode&quot; (as specified later in this document). The precise number of connections that an endpoint supports is characteristic of the gateway, and may in fact vary according to the alloction of resources within the gateway.</para>
<!--			Conference Bridge Access Point

A conference bridge endpoint is used to provide access to a specific conference. Media gateways should be able to establish several connections between the endpoint and the packet networks, or between the endpoint and other endpoints in the same gateway.  The signals originating from these connections shall be mixed according to the connection "mode", as specified later in this document.  The precise number of connections that an endpoint supports is a characteristic of the gateway, and may in fact vary according to the allocation of resources within the gateway.-->
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Packet Relay</term>
				<listitem>
					<para>A packet relay endpoint is a specific form of conference bridge that typically only supports two connections. Packet relays can be found in firewalls between a protected and an open network, or in transcoding servers used to provide interoperation between incompatible gateways, such as gateways which don't support compatible compression algorithms, or gateways that operate over different transmission networks such as IP and ATM.</para>
<!--			Packet Relay

A packet relay endpoint is a specific form of conference bridge, that typically only supports two connections.  Packets relays can be found in firewalls between a protected and an open network, or in transcoding servers used to provide interoperation between   incompatible gateways, for example gateways that do not support compatible compression algorithms, or gateways that operate over  different transmission networks such as IP and ATM.-->
				</listitem>
			</varlistentry>
		</variablelist>
		<formalpara>
			<title>Signal Generators (<acronym>SG</acronym>s) and Signal Detectors (<acronym>SD</acronym>s)</title>
			<para>This endpoint contains a set of resources which provide the media-processing functionality. It manages the interconnection of media streams between the resources, and arbitrates the flow of media stream data between them. Media services&mdash;or commands&mdash; are invoked by a client application on the endpoint; that endpoint causes the resources to perform the desired services, and directs events sent by the resources to the appropriate client. The resources in the endpoint include a primary resource and zero or more secondary resources. The primary resource is typically connected to an external media stream, and provides the data from that stream to the secondary resources. The secondary resources may process that stream (<abbrev>e.g.</abbrev> by recording it and/or performing automatic speech recognition on it), or may themselves generate generate media stream data (<abbrev>e.g.</abbrev> by playing a voice file) which is then transmitted to the primary resource.</para>
		</formalpara>
		<mediaobject
			id="mediaobj-sas-MMSArchitecture-Endpoint.gif">
			<imageobject>
				<imagedata
					align="left"
					fileref="images/sas-MMSArchitecture-Endpoint.gif"
					format="GIF" />
			</imageobject>
	<!--<caption>
		<para></para>
	</caption>-->
		</mediaobject>

<!--		
3.1.1 Signal Generators (SG) and Signal Detectors (SD)

The Endpoint contains a set of resources, which provide the media processing functionality. It manages the interconnection of media streams between the resources, and arbitrates the flow of media stream data between them. Media services (or commands) are invoked by a client application on the Endpoint; the endpoint causes the resources to perform the desired services, and directs events sent by the resources to the appropriate client. The resources in the Endpoint include a primary resource and zero or more secondary resources. The primary resource is typically connected to an external media stream, and provides the data from that stream to the secondary resources. The secondary resources may process that stream (e.g., by recording it, performing ASR on it), or may themselves generate media stream data (e.g., by playing a voice file) which is transmitted to the primary resource.-->
		<para>A resource is statically prepared if the preparation takes place at the time of creation. A resource is dynamically prepared if preparation of a particular resource (and its associated media streams) does not occur until it is required by a media operation. Static preparation can lead to less efficient usage of a server's resources, because resources may tend to be allocated for a longer time before use. However, once a resource has been prepared, it is guaranteed to be available for use. Dynamic preparation may utilize resources more efficiently because of Just-In-Time (<acronym>JIT</acronym>) allocation algorithms may be used.</para>
<!--A resource is statically prepared if preparation takes place at creation time. A resource is dynamically prepared if preparation of a particular resource (and its associated media streams) does not occur until it is required by a media operation. Static preparation can lead to less efficient usage of a serverâ€™s resources, because resources may tend to be allocated for a longer time before use. However, once a resource has been prepared, it is guaranteed to be available for use. Dynamic preparation may utilize resource more efficiently, because just-in-time (JIT) allocation algorithms may be used.-->
		<para>An endpoint is divided logically into a Service Provider Interface (<acronym>SPI</acronym>) that is used to implement specific a endpoint, and a management interface which is used for implementing manageable resources of that endpoint. All endpoints are plugged into the Mobicents <acronym>SLEE</acronym> server by registering with the MBean server. The kernel in that sense is only an aggregator, and not a source of actual functionality. The functionality is provided by the <acronym>SPI</acronym> implementation of the Mbeans, and in fact, all major endpoints are manageable MBeans interconnected through the MBean server. The best way to add endpoints to a Media Server is to write a new <acronym>JMX</acronym> bean which provides implementation of the endpoint's <acronym>SPI</acronym>.</para>
		<para>The <acronym>SPI</acronym> layer is an abstraction that endpoint providers must implement to enable their media-processing features. An implementation of <acronym>SPI</acronym> for an endpoint is referred to as an <emphasis>Endpoint Provider</emphasis>.</para>
<!--
An endpoint is divided logically into a Service Provider Interface (SPI) that is used to implement specific endpoint and a management interface which is used for implementing manageable resources of the endpoint. All endpoints are plugged into Mobicents SLEE server by registering with the MBean server. The kernel in that sense is only an aggregator, and not a source of actual functionality. The functionality is provided by SPI implementation of the MBeans, and in fact all major endpoints are manageable MBeans interconnected through the MBean server. The best way to add endpoints to a Media Server is to write a new JMX MBean which provides implementation of the endpoint's SPI.
 
The SPI layer is an abstraction that endpoint providers must implement to enable its media processing features. An implementation of SPI for an endpoint is referred as an Endpoint Provider
--> 
<!--Fig.2. Endpoint view.-->
		<figure
			id="figure-EndpointManagementMBean_UML_Diagram">
			<title>EndpointManagementMBean UML Diagram</title>
			<mediaobject>
				<imageobject>
					<imagedata
						align="center"
						width="700"
						fileref="images/sas-MMSArchictecture-dia-Endpoint.png"
						format="PNG"/>
				</imageobject>
			</mediaobject>
		</figure> 
<!--<para>All the endpoints management MBeans and trunk management MBeans extend the EndpointManagementMBean. The trunk is a collection of endpoints. The number of endpoint</para>
  	<remark>
All the endpoints management MBean and trunk management MBean extends the EndpointManagementMBean. The Trunk is collection of EndPoints. Number of EndPoint in Trunk is configured by Channels parameter. When the media server is deployed all the TrunkManagementMBean and EndPointManagementMBean are deployed from jboss-service.xml 
 
For example for AnnTrunkManagementMBean, corresponding AnnEndpointManagementMBean is created for 'channels' times and the service is started. When the start service is called on AnnEndpointManagementMBean, the corresponding AnnEndpointImpl is created and bound to JNDI using the media/trunk/Announcement/$, where $ is range from 1 to channel. 
 
Endpoint UML diagram
 
 
Each endpoint is extension of BaseEndpoint which implements Endpoint. 
AnnEndpointImpl : Is responsible for announcement and allows only one Connection at a time. It is used for playing media only. User can call
 
LoopEndpointImpl : This is used for testing the connection between the UA and media server. LoopEndpointImpl forwards the received media back to UA, so this is like echo test. 
 
 
The primary use of the Endpoint is to configure media resources in order to perform media processing (e.g., playing or recording voice files, speech recognition) on a call.The components of the Endpoint are depicted in Figure 2.  
 
 
 
ResourceManager UML
Each Endpoint is associated with its corresponding BaseResourceManager 
 
 
The MediaResource UML  
 
 
MediaSink : MediaSink is the base interface for objects that read media content and render the media to some destination
 
MediaSource : 
 
//TODO  Add the definition of each of the MediaResource
Resources are created upon request by a client. The resource configuration is defined by the client in its Session Descriptor and initial parameter settings are defined by the endpoint and used by the server to configure the resource correctly. The Media server  distinguishes between configuration and preparation. A resource is configured when its resources and media stream requirements are identified. It is prepared when the resources and media streams are exclusively allocated by the server and interconnected so as to satisfy the resource configuration. Only when a resource is prepared can it perform media services. The time at which resource preparation occurs affects the efficiency by which the server can manage its resources, as well as the failure modes that a client may experience.
 
The diagram shows the flow of how MediaResource are created and configured by Endpoint
MediaResource is in any of the four states describe below
 
//TODO define each of the states 
 
STATE_NULL :
 
STATE_CONFIGURED :
 
STATE_PREPARED :
 
STATE_STARTED : 
 -->
	</section>
	<section
		id="section-Endpoint_Identifiers">
		<title>Endpoint Identifiers</title>
		<para>The endpoint is identified by its local name. The syntax of the local name depends on the type of endpoint being named. However, the local name for each of these types is naturally hierarchical, beginning with a term which identifies the physical  gateway containing the given endpoint, and ending in a term which specifies the individual endpoint concerned.  With this in mind,  the JNDI naming rules are applied to the endpoint identifiers</para>
	</section>
	<section
		id="section-Connections">
		<title>Connections</title>
		<para>Connections are created on the call agent on each endpoint that will be involved in the "call."  In the classic example of a connection between two "DS0" endpoints (EP1 and EP2), the call agents controlling the end points will establish two connections (C1 and C2):</para>
		<mediaobject
			id="mediaobj-sas-MMSArchitecture-dia-MsConnection.jpg">
			<imageobject>
				<imagedata
					align="center"
					width="672"
					fileref="images/sas-MMSArchitecture-dia-MsConnection.jpg"
					format="JPG" />
			</imageobject>
			<caption>
				<para>Media Server Connections</para>
			</caption>
		</mediaobject>
		<para>Each connection will be designated locally by a connection identifier, and will be characterized by connection attributes.</para>
		<formalpara>
			<title>Resources and Connection Attributes</title>
			<para>Many types of resources will be associated to a connection, such as specific signal processing functions or packetization functions. Generally, these resources fall in two categories:</para>
		</formalpara>
		<variablelist
			id="varlist-Two_Types_of_Resources">
			<title>Two Types of Resources</title>
			<varlistentry>
				<term>Externally-Visible Resources</term>
				<listitem>
					<para>Externally visible resources, that affect the format of "the bits on the network" and must be communicated to the second endpoint involved in the connection.</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Internal Resources</term>
				<listitem>
					<para>Internal resources, that determine which signal is being sent over the connection and how the received signals are processed by the endpoint</para>
				</listitem>
			</varlistentry>
		</variablelist>
		<para>The resources allocated to a connection, and more generally the handling of the connection, are chosen by the media server under instructions from the call agent.  The call agent will provide these  instructions by sending two set of parameters to the media server:</para>
		<itemizedlist
			id="itemlist-Two_Sets_of_Parameters">
			<listitem>
				<para>The local directives instruct the gateway on the choice of resources that should be used for a connection.</para>
			</listitem>
			<listitem>
				<para>When available, the "session description" provided by the other end of the connection.</para>
			</listitem>
		</itemizedlist>
		<para>The local directives specify such parameters as the mode of the connection (e.g. send only, send-receive), preferred coding or packetization methods, usage of echo cancellation or silence suppression.  (A detailed list can be found in the specification of   the LocalConnectionOptions parameter of the CreateConnection command.) For each of these parameters, the call agent can either specify a value, a range of value, or no value at all.  This allow various implementations to implement various level of control, from a very tight control where the call agent specifies minute details of   the connection handling to a very loose control where the call agent only specifies broad guidelines, such as the maximum bandwidth, and let the gateway choose the detailed values.</para>
		<para>Based on the value of the local directives, the gateway will determine the resources allocated to the connection.  When this is possible, the gateway will choose values that are in line with the remote session description - but there is no absolute requirement that the parameters be exactly the same.</para>
		<para>Once the resource have been allocated, the gateway will compose a "session description" that describes the way it intends to receive packets.  Note that the session description may in some cases present a range of values.  For example, if the gateway is ready to accept one of several compression algorithm, it can provide a list of these accepted algorithms.</para>
		<formalpara
			id="fpara-Local_Connections_are_a_Special_Case">
			<title>Local Connections are a Special Case</title>
			<para>Large gateways include a large number of endpoints which are often of different types.  In some networks, we may often have to setup connections between endpoints that are located within the same gateway.  Examples of such connections may be:</para>
		</formalpara>
		<itemizedlist
			id="itemlist-Examples_of_Local_Connections">
			<listitem>
				<para>Connecting a trunk line to a wiretap device,</para>
			</listitem>
			<listitem>
				<para>Connecting a call to an Interactive Voice-Response unit</para>
			</listitem>
			<listitem>
				<para>Connecting a call to a Conferencing unit</para>
			</listitem>
			<listitem>
				<para>Routing a call from on endpoint to another, something often described as a "hairpin" connection.</para>
			</listitem>
		</itemizedlist>
		<para>Local connections are much simpler to establish than network connections. In most cases, the connection will be established through some local interconnecting device, such as for example a TDM bus.</para>
	</section>
	<section
		id="section-Events_and_Signals">
		<title>Events and Signals</title>
		<para>The concept of events and signals is central to the Media Server.  A Call Controller may ask to be notified about certain events occurring in an endpoint  (e.g., off-hook events) by passing event's identifier as parameter to endpoint's subscribe(...) method.</para>
		<para>A Call Controller may also request certain signals to be applied to an endpoint (e.g., dial-tone) by supplying the identifier of the event in as argument to endpoint's apply(...) method.</para>
		<para>Events and signals are grouped in packages, within which they share the same name space which we will refer to as event identifier in the following. Event identifiers are integer constants. Some of the events may be parametrized with additional data such as DTMF mask.</para>
		<para>Signals are divided into different types depending on their behavior:</para>
		<variablelist
			id="varlist-Types_of_Signals">
			<title>Types of Signals</title>
			<varlistentry>
				<term>On/off (OO)</term>
				<listitem>
					<para>Once applied, these signals last until they are turned off.  This can only happen as the result of a reboot/restart or a new signal request where the signal is explicitly turned off.  Signals of type OO are defined to be idempotent, thus multiple requests to turn a given OO signal on (or off) are perfectly valid.  An On/Off signal could be a visual message-waiting indicator (VMWI).  Once turned on, it MUST NOT be turned off until explicitly instructed to by the Call Agent, or as a result of an endpoint restart, i.e., these signals will not turn off as a result of the detection of a requested event.</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Time-out (TO)</term>
				<listitem>
					<para>Once applied, these signals last until they are either cancelled (by the occurrence of an event or by explicit releasing of signal generator), or a signal-specific period of time has elapsed.  A TO signal that times out will generate an "operation complete" event.  If an event occurs prior to the 180 seconds, the signal will, by default, be stopped (the "Keep signals active" action - will override this behavior).  If the signal is not stopped, the signal will time out, stop and generate an "operation complete" event, about which the server controller may or may not have requested to be notified.  A TO signal that fails after being started, but before having generated an "operation complete" event will generate an "operation failure" event which will include the name of the signal that failed.  Deletion of a connection with an active TO signal will result in such a failure.</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Brief (BR)</term>
				<listitem>
					<para>The duration of these signals is normally so short that they stop on their own.  If a signal stopping event occurs, or a new signal requests is applied, a currently active BR signal will not stop.  However, any pending BR signals not yet applied will be cancelled (a BR signal becomes pending if a signal request includes a BR signal, and there is already an active BR signal). As an example, a brief tone could be a DTMF digit. If the DTMF digit "1" is currently being played, and a signal stopping event occurs, the "1" would play to completion.  If a request to play DTMF digit "2" arrives before DTMF digit "1" finishes playing, DTMF digit "2" would become pending.</para>
				</listitem>
			</varlistentry>
		</variablelist>
		<para>Signal(s) may be generated on endpoints or on connections. To each event is associated one or more actions, which can be:</para>
		<itemizedlist
			id="itemlist-Types_of_Actions_Which_Can_Be_Associated_with_Events">
			<listitem>
				<para>Notify the event immediately, together with the accumulated list of observed events</para>
			</listitem>
			<listitem>
				<para>Accumulate the event in an event buffer, but don't notify yet</para>
			</listitem>
			<listitem>
				<para>Keep Signal(s) active</para>
			</listitem>
			<listitem>
				<para>Ignore the event</para>
			</listitem>
		</itemizedlist>
	</section>
</section>
